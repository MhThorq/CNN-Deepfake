{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxXCT9Htv+BFLr0rGa9jX+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4lFcRe83iriZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b182db-b647-4a93-de68-945e75f10160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive terhubung dan folder siap.\n",
            "Folder Dataset: /content/drive/MyDrive/Dataset-Skripsi/Dataset\n",
            "Folder Output: /content/drive/MyDrive/Dataset-Skripsi/Output\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Perintah ini akan memunculkan jendela pop-up untuk meminta izin\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Dataset-Skripsi'\n",
        "dataset_dir = os.path.join(base_dir, 'Dataset')\n",
        "output_dir = os.path.join(base_dir, 'Output')\n",
        "\n",
        "# Membuat folder jika belum ada\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Google Drive terhubung dan folder siap.\")\n",
        "print(f\"Folder Dataset: {dataset_dir}\")\n",
        "print(f\"Folder Output: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MTCNN untuk deteksi wajah\n",
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8xf9rAakrQD",
        "outputId": "da9663b5-8de2-4a8c-ec93-61cbaa622136"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.4.5 mtcnn-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Untuk Deep Learning (TensorFlow & Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Untuk Pengolahan Angka dan Gambar\n",
        "import numpy as np\n",
        "import cv2  # Ini adalah OpenCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Untuk Utilitas Sistem dan File\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# Untuk Deteksi Wajah (yang baru kita install)\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "# Untuk Evaluasi Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Semua library dasar berhasil di-impor.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWEZ1Xb3kzpT",
        "outputId": "35512975-93c4-4ae7-c925-467ff8bbffb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semua library dasar berhasil di-impor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan path output Anda (sudah didefinisikan di sel 1, tapi kita definisikan lagi di sini untuk jelas)\n",
        "output_dir = '/content/drive/MyDrive/Dataset-Skripsi/Output'\n",
        "\n",
        "# Tentukan path untuk train, validation, dan test\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "# Buat folder-folder tersebut\n",
        "for dir_path in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(os.path.join(dir_path, 'REAL'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(dir_path, 'FAKE'), exist_ok=True)\n",
        "\n",
        "print(\"Struktur folder train/validation/test telah dibuat di dalam Output.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6puoPqZk2LB",
        "outputId": "a7b358e0-6818-4d8b-b981-d1d4e1f1351c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Struktur folder train/validation/test telah dibuat di dalam Output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi detektor MTCNN\n",
        "detector = MTCNN()\n",
        "print(\"Detektor MTCNN siap digunakan.\")"
      ],
      "metadata": {
        "id": "i4fiR-LxrXje",
        "outputId": "c6249a37-913c-49e3-80ea-c343b296c009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detektor MTCNN siap digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import glob\n",
        "\n",
        "# Inisialisasi detektor lagi (untuk memastikan, jika sel terpisah)\n",
        "try:\n",
        "    detector\n",
        "except NameError:\n",
        "    detector = MTCNN()\n",
        "\n",
        "# Path dari sel 1\n",
        "dataset_dir = '/content/drive/MyDrive/Dataset-Skripsi/Dataset'\n",
        "output_dir = '/content/drive/MyDrive/Dataset-Skripsi/Output'\n",
        "\n",
        "# Tentukan berapa frame yang ingin Anda ambil per video\n",
        "# Mengambil 20 frame akan memberi Anda 20 gambar wajah per video.\n",
        "# Sesuaikan angka ini berdasarkan ukuran dataset Anda.\n",
        "FRAMES_PER_VIDEO = 20\n",
        "\n",
        "def extract_faces_from_video(video_path, output_folder, frames_to_extract):\n",
        "    \"\"\"Membaca video, mengekstrak N frame, mendeteksi wajah, dan menyimpannya.\"\"\"\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Jika video tidak bisa dibuka\n",
        "    if not video_capture.isOpened():\n",
        "        print(f\"Error: Tidak bisa membuka video {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Hitung interval frame yang akan diambil\n",
        "    if total_frames <= 0:\n",
        "        print(f\"Error: Video {video_path} tidak memiliki frame.\")\n",
        "        return\n",
        "\n",
        "    frame_interval = max(1, total_frames // frames_to_extract)\n",
        "\n",
        "    frame_count = 0\n",
        "    saved_face_count = 0\n",
        "\n",
        "    while frame_count < total_frames and saved_face_count < frames_to_extract:\n",
        "        # Set video ke frame yang diinginkan\n",
        "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
        "        success, frame = video_capture.read()\n",
        "\n",
        "        if not success:\n",
        "            frame_count += frame_interval # Lompat ke frame selanjutnya jika gagal baca\n",
        "            continue\n",
        "\n",
        "        # Konversi frame BGR (OpenCV) ke RGB (MTCNN)\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Deteksi wajah\n",
        "        faces = detector.detect_faces(frame_rgb)\n",
        "\n",
        "        if faces:\n",
        "            # Ambil wajah pertama (biasanya yang paling besar/paling jelas)\n",
        "            face_data = faces[0]\n",
        "            x, y, w, h = face_data['box']\n",
        "\n",
        "            # Pastikan koordinat tidak negatif (beberapa bug di MTCNN)\n",
        "            x, y = max(0, x), max(0, y)\n",
        "\n",
        "            # Potong (crop) wajah dari frame ASLI (BGR)\n",
        "            face_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Simpan gambar wajah\n",
        "            # Resize wajah ke ukuran standar, misal 224x224 (untuk model CNN nanti)\n",
        "            face_image_resized = cv2.resize(face_image, (224, 224))\n",
        "\n",
        "            # Buat nama file yang unik\n",
        "            video_name = os.path.basename(video_path).split('.')[0]\n",
        "            output_filename = os.path.join(output_folder, f\"{video_name}_frame_{frame_count}_face_{saved_face_count}.jpg\")\n",
        "\n",
        "            cv2.imwrite(output_filename, face_image_resized)\n",
        "            saved_face_count += 1\n",
        "\n",
        "        # Lompat ke interval frame selanjutnya\n",
        "        frame_count += frame_interval\n",
        "\n",
        "    video_capture.release()\n",
        "    # print(f\"Selesai memproses {video_path}. Total wajah disimpan: {saved_face_count}\")\n",
        "\n",
        "print(\"Fungsi extract_faces_from_video() telah didefinisikan.\")"
      ],
      "metadata": {
        "id": "mr9dEgDArZta",
        "outputId": "b10a399b-8b47-489e-c8a3-13c2fdece7a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fungsi extract_faces_from_video() telah didefinisikan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Tentukan rasio pembagian data\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# Path folder output (dari sel 4)\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "# Path folder input (Dataset)\n",
        "real_videos_path = os.path.join(dataset_dir, 'REAL')\n",
        "fake_videos_path = os.path.join(dataset_dir, 'FAKE')\n",
        "\n",
        "# Loop untuk REAL dan FAKE\n",
        "for (video_type, source_path) in [(\"REAL\", real_videos_path), (\"FAKE\", fake_videos_path)]:\n",
        "    print(f\"\\nMemulai memproses video kategori: {video_type}...\")\n",
        "\n",
        "    # Ambil semua file video (misal .mp4)\n",
        "    video_files = glob.glob(os.path.join(source_path, \"*.mp4\"))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"PERINGATAN: Tidak ada file .mp4 ditemukan di {source_path}\")\n",
        "        continue\n",
        "\n",
        "    random.shuffle(video_files) # Acak urutan video\n",
        "\n",
        "    # Hitung jumlah data untuk tiap set\n",
        "    total_videos = len(video_files)\n",
        "    train_count = int(total_videos * TRAIN_RATIO)\n",
        "    val_count = int(total_videos * VAL_RATIO)\n",
        "\n",
        "    # Bagi daftar video\n",
        "    train_videos = video_files[:train_count]\n",
        "    val_videos = video_files[train_count : train_count + val_count]\n",
        "    test_videos = video_files[train_count + val_count:]\n",
        "\n",
        "    print(f\"Total video {video_type}: {total_videos}\")\n",
        "    print(f\"Data latih (train): {len(train_videos)} video\")\n",
        "    print(f\"Data validasi (val): {len(val_videos)} video\")\n",
        "    print(f\"Data uji (test): {len(test_videos)} video\")\n",
        "\n",
        "    # Proses dan simpan ke folder yang sesuai\n",
        "    # 1. Proses TRAIN\n",
        "    print(f\"Memproses {video_type} untuk TRAIN...\")\n",
        "    output_folder_train = os.path.join(train_dir, video_type)\n",
        "    for video_file in train_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_train, FRAMES_PER_VIDEO)\n",
        "\n",
        "    # 2. Proses VALIDATION\n",
        "    print(f\"Memproses {video_type} untuk VALIDATION...\")\n",
        "    output_folder_val = os.path.join(val_dir, video_type)\n",
        "    for video_file in val_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_val, FRAMES_PER_VIDEO)\n",
        "\n",
        "    # 3. Proses TEST\n",
        "    print(f\"Memproses {video_type} untuk TEST...\")\n",
        "    output_folder_test = os.path.join(test_dir, video_type)\n",
        "    for video_file in test_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_test, FRAMES_PER_VIDEO)\n",
        "\n",
        "print(\"\\n--- PROSES EKSTRAKSI SELESAI ---\")"
      ],
      "metadata": {
        "id": "uHIzrJMvrbTX",
        "outputId": "bbb8d955-dcdf-4c80-c939-c47a6af51070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Memulai memproses video kategori: REAL...\n",
            "PERINGATAN: Tidak ada file .mp4 ditemukan di /content/drive/MyDrive/Dataset-Skripsi/Dataset/REAL\n",
            "\n",
            "Memulai memproses video kategori: FAKE...\n",
            "PERINGATAN: Tidak ada file .mp4 ditemukan di /content/drive/MyDrive/Dataset-Skripsi/Dataset/FAKE\n",
            "\n",
            "--- PROSES EKSTRAKSI SELESAI ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFCTxa1Vrdxe"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}