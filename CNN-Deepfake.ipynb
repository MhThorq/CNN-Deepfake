{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaOeE4U7usNAz2rb8gWkE6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lFcRe83iriZ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Perintah ini akan memunculkan jendela pop-up untuk meminta izin\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Dataset-Skripsi'\n",
        "dataset_dir = os.path.join(base_dir, 'Dataset')\n",
        "output_dir = os.path.join(base_dir, 'Output')\n",
        "\n",
        "# Membuat folder jika belum ada\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Google Drive terhubung dan folder siap.\")\n",
        "print(f\"Folder Dataset: {dataset_dir}\")\n",
        "print(f\"Folder Output: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MTCNN untuk deteksi wajah\n",
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "i8xf9rAakrQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Untuk Deep Learning (TensorFlow & Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Untuk Pengolahan Angka dan Gambar\n",
        "import numpy as np\n",
        "import cv2  # Ini adalah OpenCV\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Untuk Utilitas Sistem dan File\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# Untuk Deteksi Wajah (yang baru kita install)\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "# Untuk Evaluasi Model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Semua library dasar berhasil di-impor.\")"
      ],
      "metadata": {
        "id": "CWEZ1Xb3kzpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan path output Anda (sudah didefinisikan di sel 1, tapi kita definisikan lagi di sini untuk jelas)\n",
        "output_dir = '/content/drive/MyDrive/Dataset-Skripsi/Output'\n",
        "\n",
        "# Tentukan path untuk train, validation, dan test\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "print(\"Struktur folder train/validation/test telah dibuat di dalam Output.\")"
      ],
      "metadata": {
        "id": "m6puoPqZk2LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi detektor MTCNN\n",
        "detector = MTCNN()\n",
        "print(\"Detektor MTCNN siap digunakan.\")"
      ],
      "metadata": {
        "id": "i4fiR-LxrXje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import glob\n",
        "\n",
        "# Inisialisasi detektor lagi (untuk memastikan, jika sel terpisah)\n",
        "try:\n",
        "    detector\n",
        "except NameError:\n",
        "    detector = MTCNN()\n",
        "\n",
        "# Path dari sel 1\n",
        "dataset_dir = '/content/drive/MyDrive/Dataset-Skripsi/Dataset'\n",
        "output_dir = '/content/drive/MyDrive/Dataset-Skripsi/Output'\n",
        "\n",
        "# Tentukan berapa frame yang ingin Anda ambil per video\n",
        "# Mengambil 20 frame akan memberi Anda 20 gambar wajah per video.\n",
        "# Sesuaikan angka ini berdasarkan ukuran dataset Anda.\n",
        "FRAMES_PER_VIDEO = 20\n",
        "\n",
        "def extract_faces_from_video(video_path, output_folder, frames_to_extract):\n",
        "    \"\"\"Membaca video, mengekstrak N frame, mendeteksi wajah, dan menyimpannya.\"\"\"\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Jika video tidak bisa dibuka\n",
        "    if not video_capture.isOpened():\n",
        "        print(f\"Error: Tidak bisa membuka video {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Hitung interval frame yang akan diambil\n",
        "    if total_frames <= 0:\n",
        "        print(f\"Error: Video {video_path} tidak memiliki frame.\")\n",
        "        return\n",
        "\n",
        "    frame_interval = max(1, total_frames // frames_to_extract)\n",
        "\n",
        "    frame_count = 0\n",
        "    saved_face_count = 0\n",
        "\n",
        "    while frame_count < total_frames and saved_face_count < frames_to_extract:\n",
        "        # Set video ke frame yang diinginkan\n",
        "        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
        "        success, frame = video_capture.read()\n",
        "\n",
        "        if not success:\n",
        "            frame_count += frame_interval # Lompat ke frame selanjutnya jika gagal baca\n",
        "            continue\n",
        "\n",
        "        # Konversi frame BGR (OpenCV) ke RGB (MTCNN)\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Deteksi wajah\n",
        "        faces = detector.detect_faces(frame_rgb)\n",
        "\n",
        "        if faces:\n",
        "            # Ambil wajah pertama (biasanya yang paling besar/paling jelas)\n",
        "            face_data = faces[0]\n",
        "            x, y, w, h = face_data['box']\n",
        "\n",
        "            # Pastikan koordinat tidak negatif (beberapa bug di MTCNN)\n",
        "            x, y = max(0, x), max(0, y)\n",
        "\n",
        "            # Potong (crop) wajah dari frame ASLI (BGR)\n",
        "            face_image = frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Simpan gambar wajah\n",
        "            # Resize wajah ke ukuran standar, misal 224x224 (untuk model CNN nanti)\n",
        "            face_image_resized = cv2.resize(face_image, (224, 224))\n",
        "\n",
        "            # Buat nama file yang unik\n",
        "            video_name = os.path.basename(video_path).split('.')[0]\n",
        "            output_filename = os.path.join(output_folder, f\"{video_name}_frame_{frame_count}_face_{saved_face_count}.jpg\")\n",
        "\n",
        "            cv2.imwrite(output_filename, face_image_resized)\n",
        "            saved_face_count += 1\n",
        "\n",
        "        # Lompat ke interval frame selanjutnya\n",
        "        frame_count += frame_interval\n",
        "\n",
        "    video_capture.release()\n",
        "    # print(f\"Selesai memproses {video_path}. Total wajah disimpan: {saved_face_count}\")\n",
        "\n",
        "print(\"Fungsi extract_faces_from_video() telah didefinisikan.\")"
      ],
      "metadata": {
        "id": "mr9dEgDArZta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os # Pastikan os sudah diimpor, yang sudah ada di sel awal\n",
        "\n",
        "# Tentukan rasio pembagian data\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# Path folder output (dari sel 4)\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "# Path folder input (Dataset)\n",
        "real_videos_path = os.path.join(dataset_dir, 'Celeb-real')\n",
        "fake_videos_path = os.path.join(dataset_dir, 'Celeb-synthesis')\n",
        "\n",
        "# Loop untuk REAL dan FAKE\n",
        "for (video_type, source_path) in [(\"Celeb-real\", real_videos_path), (\"Celeb-synthesis\", fake_videos_path)]:\n",
        "    print(f\"\\nMemulai memproses video kategori: {video_type}...\")\n",
        "\n",
        "    # Ambil semua file video (misal .mp4)\n",
        "    video_files = glob.glob(os.path.join(source_path, \"*.mp4\"))\n",
        "\n",
        "    if not video_files:\n",
        "        print(f\"PERINGATAN: Tidak ada file .mp4 ditemukan di {source_path}\")\n",
        "        continue\n",
        "\n",
        "    random.shuffle(video_files) # Acak urutan video\n",
        "\n",
        "    # Hitung jumlah data untuk tiap set\n",
        "    total_videos = len(video_files)\n",
        "    train_count = int(total_videos * TRAIN_RATIO)\n",
        "    val_count = int(total_videos * VAL_RATIO)\n",
        "\n",
        "    # Bagi daftar video\n",
        "    train_videos = video_files[:train_count]\n",
        "    val_videos = video_files[train_count : train_count + val_count]\n",
        "    test_videos = video_files[train_count + val_count:]\n",
        "\n",
        "    print(f\"Total video {video_type}: {total_videos}\")\n",
        "    print(f\"Data latih (train): {len(train_videos)} video\")\n",
        "    print(f\"Data validasi (val): {len(val_videos)} video\")\n",
        "    print(f\"Data uji (test): {len(test_videos)} video\")\n",
        "\n",
        "    # Proses dan simpan ke folder yang sesuai\n",
        "    # 1. Proses TRAIN\n",
        "    print(f\"Memproses {video_type} untuk TRAIN...\")\n",
        "    output_folder_train = os.path.join(train_dir, video_type)\n",
        "    os.makedirs(output_folder_train, exist_ok=True) # Tambahkan ini untuk membuat folder kelas\n",
        "    for video_file in train_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_train, FRAMES_PER_VIDEO)\n",
        "\n",
        "    # 2. Proses VALIDATION\n",
        "    print(f\"Memproses {video_type} untuk VALIDATION...\")\n",
        "    output_folder_val = os.path.join(val_dir, video_type)\n",
        "    os.makedirs(output_folder_val, exist_ok=True) # Tambahkan ini untuk membuat folder kelas\n",
        "    for video_file in val_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_val, FRAMES_PER_VIDEO)\n",
        "\n",
        "    # 3. Proses TEST\n",
        "    print(f\"Memproses {video_type} untuk TEST...\")\n",
        "    output_folder_test = os.path.join(test_dir, video_type)\n",
        "    os.makedirs(output_folder_test, exist_ok=True) # Tambahkan ini untuk membuat folder kelas\n",
        "    for video_file in test_videos:\n",
        "        extract_faces_from_video(video_file, output_folder_test, FRAMES_PER_VIDEO)\n",
        "\n",
        "print(\"\\n--- PROSES EKSTRAKSI SELESAI ---\")"
      ],
      "metadata": {
        "id": "uHIzrJMvrbTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan path dari Fase 1\n",
        "output_dir = '/content/drive/MyDrive/Dataset-Skripsi/Output'\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "test_dir = os.path.join(output_dir, 'test')\n",
        "\n",
        "# Tentukan parameter gambar\n",
        "# Ukuran ini HARUS SAMA dengan yang Anda gunakan di Fase 1 (224x224)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32 # Berapa gambar yang dimuat sekaligus\n",
        "\n",
        "# 1. Generator untuk Data Latih (dengan Augmentasi)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,             # Normalisasi piksel dari 0-255 ke 0-1\n",
        "    rotation_range=20,          # Putar gambar secara acak\n",
        "    width_shift_range=0.2,      # Geser horizontal\n",
        "    height_shift_range=0.2,     # Geser vertikal\n",
        "    shear_range=0.2,            # Miringkan gambar\n",
        "    zoom_range=0.2,             # Zoom gambar\n",
        "    horizontal_flip=True,       # Balik gambar secara horizontal\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 2. Generator untuk Data Validasi & Tes (TANPA Augmentasi, hanya rescale)\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 3. Buat 'Pipa' yang membaca dari folder\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary' # Karena kita punya 2 kelas: REAL vs FAKE\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False # Tidak perlu diacak untuk validasi\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False # Tidak perlu diacak untuk tes\n",
        ")\n",
        "\n",
        "print(f\"Kelas ditemukan: {train_generator.class_indices}\")"
      ],
      "metadata": {
        "id": "JFCTxa1Vrdxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "\n",
        "# Tentukan ukuran input\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# 1. Muat Model Dasar (XceptionNet)\n",
        "# include_top=False berarti kita tidak menyertakan lapisan klasifikasi aslinya\n",
        "# weights='imagenet' berarti kita memuat bobot yang sudah terlatih\n",
        "base_model_xception = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# 2. Bekukan lapisan dasar\n",
        "# Kita tidak ingin melatih ulang lapisan yang sudah pintar ini (untuk saat ini)\n",
        "base_model_xception.trainable = False\n",
        "\n",
        "# 3. Tambahkan 'Kepala' (Head) baru kita di atas model dasar\n",
        "x = base_model_xception.output\n",
        "x = GlobalAveragePooling2D()(x) # Meratakan output fitur\n",
        "x = Dense(1024, activation='relu')(x) # Lapisan tersembunyi (hidden layer)\n",
        "x = Dropout(0.5)(x) # Mencegah overfitting\n",
        "# Lapisan output: 1 neuron dengan aktivasi sigmoid (menghasilkan angka 0-1)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# 4. Gabungkan menjadi model akhir\n",
        "model_xception = Model(inputs=base_model_xception.input, outputs=predictions)\n",
        "\n",
        "# 5. Kompilasi Model\n",
        "# Kita gunakan 'binary_crossentropy' karena ini masalah 2 kelas (REAL vs FAKE)\n",
        "model_xception.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # Gunakan learning rate kecil\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Tampilkan arsitektur model\n",
        "model_xception.summary()"
      ],
      "metadata": {
        "id": "ICADiSySOaeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan berapa epoch (putaran) Anda ingin melatih\n",
        "EPOCHS = 10 # Mulai dengan 10, Anda bisa tambah nanti\n",
        "\n",
        "# Hitung jumlah langkah per epoch\n",
        "# Ini penting agar Keras tahu berapa banyak batch yang harus diambil\n",
        "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
        "validation_steps = validation_generator.samples // BATCH_SIZE\n",
        "\n",
        "print(f\"Total langkah per epoch (train): {steps_per_epoch}\")\n",
        "print(f\"Total langkah validasi: {validation_steps}\")\n",
        "\n",
        "# Mulai pelatihan!\n",
        "history_xception = model_xception.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n",
        "\n",
        "print(\"\\n--- PELATIHAN XCEPTIONNET SELESAI ---\")"
      ],
      "metadata": {
        "id": "Me2mCyGpOg1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model yang sudah dilatih\n",
        "model_path_xception = os.path.join(output_dir, 'model_xception_final.h5')\n",
        "model_xception.save(model_path_xception)\n",
        "print(f\"Model XceptionNet disimpan di: {model_path_xception}\")\n",
        "\n",
        "# Simpan riwayat pelatihan (untuk dibuat grafik nanti)\n",
        "import pickle # Pickle digunakan untuk menyimpan objek Python\n",
        "\n",
        "history_path_xception = os.path.join(output_dir, 'history_xception.pkl')\n",
        "with open(history_path_xception, 'wb') as f:\n",
        "    pickle.dump(history_xception.history, f)\n",
        "\n",
        "print(f\"Riwayat pelatihan disimpan di: {history_path_xception}\")\n",
        "\n",
        "# --- (OPSIONAL) Plot Grafik Pelatihan ---\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Akurasi\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_xception.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_xception.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Akurasi Model XceptionNet')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_xception.history['loss'], label='Training Loss')\n",
        "plt.plot(history_xception.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Model XceptionNet')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "68Pkvnv1_Ieu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}